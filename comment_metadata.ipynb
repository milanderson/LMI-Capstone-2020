{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Elaticsearch Results\n",
    "## LMI Capstone Team\n",
    "## Summer Chambers | Steve Morris | Kaleb Shikur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from statistics import mode\n",
    "from sklearn.metrics import ndcg_score, f1_score, average_precision_score\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_url = \"https://mikeanders.org/data/CMS/CMS-2018-0101-0001/CMS-1701-P%20Comment%20MetaData.csv\"\n",
    "data = pd.read_csv(metadata_url, usecols=range(0,36))[:469] #ignore last few columns and blank rows at end of csv \n",
    "data = data.rename(columns=lambda x: x.strip()) #strip whitespace from columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data10 = data.fillna(0) #fill NaN with 0\n",
    "\n",
    "section_cols = data10.columns[3:] \n",
    "data10[section_cols] = data10[section_cols].replace([\"Y\"], 1) #replace Y with 1 in approriate columns\n",
    "data11 = data10.copy()\n",
    "section_cols1  = data11.columns[3:] \n",
    "data11[section_cols1] = np.where((data11[section_cols1]  != 1), 0, data11[section_cols1])\n",
    "\n",
    "# Combining columns for index matching: (A6b, A6b.1, = A6b),  (C3b, C3b.1'= C3b) ('A7', 'A7.1', 'A7.2', = A7b, a7c),  (F = F2, F3)\n",
    "\n",
    "data11['A6b'] = (data11['A6b'] + data11['A6b.1'])\n",
    "data11['A6b'] = data11['A6b'].replace(2,1)\n",
    "data11['C3b'] = (data11['C3b'] + data11['C3b.1'])\n",
    "data11['C3b'] = data11['C3b'].replace(2,1)\n",
    "data11['A7'] = (data11['A7'] + data11['A7.1'] + data11['A7.2'])\n",
    "data11['A7'] = data11['A7'].replace(2,1)\n",
    "data11['A7'] = data11['A7'].replace(3,1)\n",
    "\n",
    "data11 = data11.drop(['A6b.1', 'C3b.1', 'A7.1', 'A7.2'], axis=1)\n",
    "data11 = data11[0:468]\n",
    "data11.Name = [name.split('DRAFT-')[1].split('-')[0] for name in data11.Name]\n",
    "data11 = data11.rename(columns=lambda x: x.lower())\n",
    "section_cols1 = data11.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>organization name / submitter name</th>\n",
       "      <th>submitter state</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4b</th>\n",
       "      <th>a4c</th>\n",
       "      <th>a5b</th>\n",
       "      <th>a5c</th>\n",
       "      <th>a5d</th>\n",
       "      <th>...</th>\n",
       "      <th>d3c</th>\n",
       "      <th>d3d</th>\n",
       "      <th>d4</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>e6</th>\n",
       "      <th>e7</th>\n",
       "      <th>f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002</td>\n",
       "      <td>Erick Meleher</td>\n",
       "      <td>NC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003</td>\n",
       "      <td>Mayank Shah</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004</td>\n",
       "      <td>Mayank Shah</td>\n",
       "      <td>IL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005</td>\n",
       "      <td>Morey Menacker</td>\n",
       "      <td>NJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0006</td>\n",
       "      <td>Todd Rapoza</td>\n",
       "      <td>MA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0465</td>\n",
       "      <td>Morehouse Choice Accountable Care Organization...</td>\n",
       "      <td>GA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0466</td>\n",
       "      <td>Liberty ACO</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0467</td>\n",
       "      <td>Washington State Hospital Association</td>\n",
       "      <td>WA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0468</td>\n",
       "      <td>Think Whole Person Healthcare</td>\n",
       "      <td>NE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0469</td>\n",
       "      <td>Palm Beach Accountable Care Organization</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name                 organization name / submitter name submitter state  \\\n",
       "0    0002                                      Erick Meleher              NC   \n",
       "1    0003                                        Mayank Shah              IL   \n",
       "2    0004                                        Mayank Shah              IL   \n",
       "3    0005                                     Morey Menacker              NJ   \n",
       "4    0006                                        Todd Rapoza              MA   \n",
       "..    ...                                                ...             ...   \n",
       "463  0465  Morehouse Choice Accountable Care Organization...              GA   \n",
       "464  0466                                        Liberty ACO              TX   \n",
       "465  0467              Washington State Hospital Association              WA   \n",
       "466  0468                      Think Whole Person Healthcare              NE   \n",
       "467  0469           Palm Beach Accountable Care Organization              FL   \n",
       "\n",
       "     a2  a3  a4b  a4c  a5b  a5c  a5d  ...  d3c  d3d  d4  e2  e3  e4  e5  e6  \\\n",
       "0     0   0    0    0    0    0    0  ...    0    0   0   0   0   0   0   0   \n",
       "1     0   0    0    0    0    0    0  ...    1    0   0   0   0   0   1   0   \n",
       "2     0   0    0    0    0    0    0  ...    0    0   0   0   0   0   0   0   \n",
       "3     0   0    0    0    1    0    0  ...    0    0   0   0   0   0   0   0   \n",
       "4     0   0    0    0    0    0    0  ...    0    0   0   0   0   0   0   0   \n",
       "..   ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..   \n",
       "463   1   1    0    0    1    0    1  ...    1    0   0   0   0   0   0   1   \n",
       "464   0   1    0    0    0    0    0  ...    0    0   0   0   0   0   0   0   \n",
       "465   0   0    0    0    0    0    0  ...    0    0   0   0   0   0   0   0   \n",
       "466   1   0    0    0    0    0    0  ...    0    0   0   0   0   0   0   0   \n",
       "467   0   1    0    1    1    1    0  ...    1    0   0   0   1   1   0   1   \n",
       "\n",
       "     e7  f  \n",
       "0     0  0  \n",
       "1     0  0  \n",
       "2     0  0  \n",
       "3     0  0  \n",
       "4     0  1  \n",
       "..   .. ..  \n",
       "463   0  0  \n",
       "464   0  0  \n",
       "465   0  0  \n",
       "466   0  0  \n",
       "467   0  0  \n",
       "\n",
       "[468 rows x 32 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_dict = {} # initiate dict\n",
    "for i, name in enumerate(data11.name): # iterate through Comment Names\n",
    "    dict1 = {col:data11[col].iloc[i] for col in section_cols1} # locate this row's values for each column\n",
    "    list1 = [key for key,value in dict1.items() if value==1] # create list of matching sections for this row\n",
    "    truth_dict[name] = list1 # add Comment Name and list of matching sections to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unique_comments2018.json\") as f:\n",
    "    unique_comments2018 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_data = data11.loc[data11['name'].isin(unique_comments2018.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_truth_dict = {} # initiate dict\n",
    "for i, name in enumerate(unique_data.name): # iterate through Comment Names\n",
    "    dict1 = {col:unique_data[col].iloc[i] for col in section_cols1} # locate this row's values for each column\n",
    "    list1 = [key for key,value in dict1.items() if value==1] # create list of matching sections for this row\n",
    "    unique_truth_dict[name] = list1 # add Comment Name and list of matching sections to dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump = json.dumps(unique_truth_dict)\n",
    "f = open('unique_truth_dict.json','w')\n",
    "f.write(dump)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_matches = {key: len(value) for key, value in unique_truth_dict.items()}\n",
    "mode(list(num_matches.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define true rule section names\n",
    "truth_keys = list(section_cols1)\n",
    "truth_keys = [key1.lower() for key1 in truth_keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header Index Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('header_results.json') as f:\n",
    "    header_results_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranlate ES keys to true rule section names, MAINTAINING ORDER\n",
    "for key, value in header_results_json.items():\n",
    "    value_list = []\n",
    "    for val_idx in value:\n",
    "        for true_key in truth_keys:\n",
    "            if true_key in val_idx and true_key not in value_list: \n",
    "                value_list.append(true_key)\n",
    "        header_results_json[key]=value_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_dict shows all true positives, without penalty to false categorization\n",
    "match_dict= {}\n",
    "for (key1, value1), (key2,value2) in zip(truth_dict.items(), header_results_json.items()):\n",
    "    match_count = 0\n",
    "    for val_idx in value1:\n",
    "        if val_idx in value2:\n",
    "            match_count += 1\n",
    "        match_dict[key1]=match_count/len(value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpenalized accuracy of true positives\n",
    "meanvals = np.mean(list(match_dict.values()))\n",
    "meanvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_dict1 shows all true positives, with penalty to false categorization\n",
    "match_dict1= {}\n",
    "for (key1, value1), (key2,value2) in zip(truth_dict.items(), header_results_json.items()):\n",
    "    match_count = 0\n",
    "    for val_idx in value2:\n",
    "        if val_idx in value1:\n",
    "            match_count += 1\n",
    "        match_dict1[key1]=match_count/len(value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penalized accuracy of true positives\n",
    "meanvals1 = np.mean(list(match_dict1.values()))\n",
    "meanvals1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([meanvals,meanvals1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn NDCG Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create truth dict with values equal to sparse array length=29, binary\n",
    "truth_dict_all = truth_dict.copy()\n",
    "for key, value in truth_dict.items():\n",
    "    new_value_list = np.zeros(len(truth_keys))\n",
    "    for val in value:\n",
    "        for i in range(len(truth_keys)):\n",
    "            if val == truth_keys[i]:\n",
    "                new_value_list[i] = 1\n",
    "    truth_dict_all[key] = new_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create header results dict with values equal to sparse array length=29, binary\n",
    "binary_header_results_all = header_results_json.copy()\n",
    "for key, value in header_results_json.items():\n",
    "    new_value_list = np.zeros(len(truth_keys))\n",
    "    counter = 1\n",
    "    for val in value:\n",
    "        for i in range(len(truth_keys)):\n",
    "            if val == truth_keys[i]:\n",
    "                counter += 1\n",
    "                new_value_list[i] = 1\n",
    "    binary_header_results_all[key] = new_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create header results dict with values equal to sparse array length=29, (discounted)\n",
    "header_results_all = header_results_json.copy()\n",
    "for key, value in header_results_json.items():\n",
    "    new_value_list = np.zeros(len(truth_keys))\n",
    "    counter = 1\n",
    "    for val in value:\n",
    "        for i in range(len(truth_keys)):\n",
    "            if val == truth_keys[i]:\n",
    "                counter += 1\n",
    "                new_value_list[i] = 1/math.log(counter, 2)\n",
    "    header_results_all[key] = new_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_ndcg = {}\n",
    "headers_ap = {}\n",
    "headers_f1 = {}\n",
    "for (true_key, true_value), (es_key, es_value) in zip(truth_dict_all.items(), header_results_all.items()):\n",
    "    headers_ndcg[true_key] = ndcg_score([true_value], [es_value])\n",
    "    headers_ap[true_key] = average_precision_score(true_value, es_value, pos_label=0)\n",
    "for (true_key, true_value), (es_key, es_value) in zip(truth_dict_all.items(), binary_header_results_all.items()):\n",
    "    headers_f1[true_key] = f1_score(true_value, es_value, zero_division=0, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_eval = pd.DataFrame(data=[headers_ndcg, headers_ap, headers_f1]).T\n",
    "headers_eval = headers_eval.rename({0:\"NDCG\", 1:\"AP\", 2:\"F1\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "sns.kdeplot(headers_eval.NDCG, alpha=.1, shade=True, label='NDCG')\n",
    "sns.kdeplot(headers_eval.AP, alpha=.1, shade=True,label='AP')\n",
    "sns.kdeplot(headers_eval.F1,  alpha=.1, shade=True,label='F1')\n",
    "plt.legend()\n",
    "plt.title('Ranking Metric Performance, Headers Index', fontsize=20)\n",
    "plt.xlabel('Score Distribution', fontsize=16)\n",
    "plt.ylabel('Score Density', fontsize=16)\n",
    "plt.xlim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which comments were scored poorly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"comments2018.json\") as f:\n",
    "    comments2018 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorf1 = headers_eval.query(\"F1 < 0.5\").F1\n",
    "poorf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorndcg = headers_eval.query(\"NDCG < 0.3 & NDCG > 0\").NDCG\n",
    "poorndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorf1_comments = {key:comment for key, comment in comments2018.items() if key in poorf1}\n",
    "{key:len(comment) for key, comment in poorf1_comments.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorf1_comments_truth = {key:matches for key, matches in truth_dict.items() if key in poorf1}\n",
    "poorf1_comments_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorndcg_comments = {key:comment for key, comment in comments2018.items() if key in poorndcg}\n",
    "{key:len(comment) for key, comment in poorndcg_comments.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorndcg_comments_truth = {key:matches for key, matches in truth_dict.items() if key in poorndcg}\n",
    "poorndcg_comments_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headers Unique Index Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unique_header_results.json') as f:\n",
    "    unique_header_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranlate ES keys to true rule section names, MAINTAINING ORDER\n",
    "for key, value in unique_header_results.items():\n",
    "    value_list = []\n",
    "    for val_idx in value:\n",
    "        for true_key in truth_keys:\n",
    "            if true_key in val_idx and true_key not in value_list: \n",
    "                value_list.append(true_key)\n",
    "        unique_header_results[key]=value_list     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0002': ['a4c', 'a6c', 'a5c', 'c3b', 'c2', 'a3', 'a5b', 'a2', 'e4', 'a7'],\n",
       " '0003': ['a4c', 'a6c', 'a3', 'a5c', 'e4', 'c3b', 'a5b', 'a2', 'c2', 'a7'],\n",
       " '0004': ['a4c', 'a6c', 'a5c', 'a3', 'e4', 'a7', 'c2', 'a2', 'a5b', 'c3b'],\n",
       " '0005': ['a4c', 'a6c', 'a5b', 'a5c', 'c2', 'c3b', 'a3', 'e4', 'a2', 'b2a'],\n",
       " '0006': ['a4c', 'a6c', 'a5c', 'a3', 'a2', 'a7', 'a5b', 'c2', 'b2a'],\n",
       " '0007': ['a4c', 'a6c', 'c3b', 'a5c', 'a5b', 'c2', 'e4', 'a3', 'a7', 'a2'],\n",
       " '0008': ['a4c', 'a6c', 'c3b', 'a5b', 'c2', 'a5c', 'a3', 'e4', 'b2a', 'b2b'],\n",
       " '0009': ['a4c', 'a6c', 'c3b', 'a5c', 'a5b', 'a3', 'e4', 'a7', 'c2', 'b2a'],\n",
       " '0010': ['a4c', 'a6c', 'a5b', 'a5c', 'a3', 'c3b', 'e6', 'a2', 'b2a', 'e4'],\n",
       " '0011': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0012': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0013': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0014': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0016': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0042': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0077': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0081': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0110': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0115': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0126': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0138': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0157': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0170': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0172': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0176': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0182': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0189': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0190': ['a4c', 'a6c', 'a5c', 'a5b', 'a3', 'c2', 'c3b', 'e4', 'a7', 'a2'],\n",
       " '0191': ['a4c', 'a6c', 'a5c', 'a5b', 'a7', 'c2', 'a3', 'a2', 'c3b', 'e4'],\n",
       " '0195': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0197': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0204': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0207': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0208': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0209': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0211': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0212': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0221': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0226': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0229': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0233': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0234': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0238': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0239': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0240': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0241': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0243': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0247': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0249': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0256': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0258': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0261': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0267': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0268': ['a4c', 'a6c', 'a5b', 'c3b', 'e4', 'a5c', 'c2', 'a3', 'a7', 'e5'],\n",
       " '0271': ['a4c', 'a6c', 'a5c', 'a3', 'c3b', 'a2', 'a5b', 'e4', 'a7', 'c2'],\n",
       " '0287': ['a4c', 'a6c', 'a5b', 'a5c', 'c3b', 'a2', 'a3', 'e4', 'a7', 'c2'],\n",
       " '0297': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0301': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0304': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0308': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0322': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0326': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0331': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0336': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0346': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0347': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0353': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0357': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0359': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0361': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0362': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0374': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0376': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0383': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0385': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0386': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0394': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0404': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0408': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0419': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0423': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0428': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0437': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0438': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b'],\n",
       " '0467': ['a4c', 'a6c', 'a5c', 'a3', 'a7', 'c3b', 'a5b', 'a2', 'e4', 'a6b']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_header_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create truth dict with values equal to sparse array length=29, binary\n",
    "unique_truth_dict_all = unique_truth_dict.copy()\n",
    "for key, value in unique_truth_dict.items():\n",
    "    new_value_list = np.zeros(len(truth_keys))\n",
    "    for val in value:\n",
    "        for i in range(len(truth_keys)):\n",
    "            if val == truth_keys[i]:\n",
    "                new_value_list[i] = 1\n",
    "    unique_truth_dict_all[key] = new_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create header results dict with values equal to sparse array length=29, (discounted)\n",
    "unique_header_results_all = unique_header_results.copy()\n",
    "for key, value in unique_header_results.items():\n",
    "    new_value_list = np.zeros(len(truth_keys))\n",
    "    counter = 1\n",
    "    for val in value:\n",
    "        for i in range(len(truth_keys)):\n",
    "            if val == truth_keys[i]:\n",
    "                counter += 1\n",
    "                new_value_list[i] = 1/math.log(counter, 2)\n",
    "    unique_header_results_all[key] = new_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create header results dict with values equal to sparse array length=29, binary\n",
    "unique_binary_header_results_all = unique_header_results.copy()\n",
    "for key, value in unique_header_results.items():\n",
    "    new_value_list = np.zeros(len(truth_keys))\n",
    "    counter = 1\n",
    "    for val in value:\n",
    "        for i in range(len(truth_keys)):\n",
    "            if val == truth_keys[i]:\n",
    "                counter += 1\n",
    "                new_value_list[i] = 1\n",
    "    unique_binary_header_results_all[key] = new_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_headers_ndcg = {}\n",
    "unique_headers_ap = {}\n",
    "unique_headers_f1 = {}\n",
    "for (true_key, true_value), (es_key, es_value) in zip(unique_truth_dict_all.items(), unique_header_results_all.items()):\n",
    "    unique_headers_ndcg[true_key] = ndcg_score([true_value], [es_value])\n",
    "    unique_headers_ap[true_key] = average_precision_score(true_value, es_value, pos_label=0)\n",
    "for (true_key, true_value), (es_key, es_value) in zip(unique_truth_dict_all.items(), unique_binary_header_results_all.items()):\n",
    "    unique_headers_f1[true_key] = f1_score(true_value, es_value, zero_division=0, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_headers_eval = pd.DataFrame(data=[unique_headers_ndcg, unique_headers_ap, unique_headers_f1]).T\n",
    "unique_headers_eval = unique_headers_eval.rename({0:\"NDCG\", 1:\"AP\", 2:\"F1\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDCG</th>\n",
       "      <th>AP</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.517658</td>\n",
       "      <td>0.800936</td>\n",
       "      <td>0.736477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.266236</td>\n",
       "      <td>0.214707</td>\n",
       "      <td>0.105832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.319753</td>\n",
       "      <td>0.733155</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.501266</td>\n",
       "      <td>0.888425</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.726067</td>\n",
       "      <td>0.956577</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.993542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.837209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NDCG         AP         F1\n",
       "count  85.000000  85.000000  85.000000\n",
       "mean    0.517658   0.800936   0.736477\n",
       "std     0.266236   0.214707   0.105832\n",
       "min     0.000000   0.068966   0.190476\n",
       "25%     0.319753   0.733155   0.702703\n",
       "50%     0.501266   0.888425   0.765957\n",
       "75%     0.726067   0.956577   0.800000\n",
       "max     0.993542   1.000000   0.837209"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_headers_eval.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Index Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hybrid_results.json') as f1:\n",
    "    hybrid_results_json = json.load(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tranlate ES keys to true rule section names, MAINTAINING ORDER\n",
    "for key, value in hybrid_results_json.items():\n",
    "    value_list = []\n",
    "    for val_idx in value:\n",
    "        for true_key in truth_keys:\n",
    "            if true_key in val_idx[0:4] and true_key not in value_list:\n",
    "                    value_list.append(true_key)\n",
    "        hybrid_results_json[key]=value_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_dict shows all true positives, without penalty to false categorization\n",
    "match_dict= {}\n",
    "for (key1, value1), (key2, value2) in zip(truth_dict.items(), hybrid_results_json.items()):\n",
    "    match_count = 0\n",
    "    for val_idx in value1:\n",
    "            if val_idx in value2:\n",
    "                match_count += 1\n",
    "            match_dict[key1]=match_count/len(value1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpenalized accuracy of true positives\n",
    "meanvals = np.mean(list(match_dict.values()))\n",
    "meanvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match_dict1 shows all true positives, with penalty to false categorization\n",
    "match_dict1= {}\n",
    "for (key1, value1), (key2,value2) in zip(truth_dict.items(), hybrid_results_json.items()):\n",
    "    match_count = 0\n",
    "    for val_idx in value2:\n",
    "        if val_idx in value1:\n",
    "            match_count += 1\n",
    "        match_dict1[key1]=match_count/len(value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penalized accuracy of true positives\n",
    "meanvals1 = np.mean(list(match_dict1.values()))\n",
    "meanvals1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([meanvals,meanvals1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn NDCG Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create header results dict with values equal to sparse array length=29, binary\n",
    "binary_hybrid_results_all = hybrid_results_json.copy()\n",
    "for key, value in hybrid_results_json.items():\n",
    "    new_value_list = np.zeros(len(truth_keys))\n",
    "    for val in value:\n",
    "        for i in range(len(truth_keys)):\n",
    "            if val == truth_keys[i]:\n",
    "                new_value_list[i] = 1\n",
    "    binary_hybrid_results_all[key] = new_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create header results dict with values equal to sparse array length=29, binary (discounted)\n",
    "hybrid_results_all = hybrid_results_json.copy()\n",
    "for key, value in hybrid_results_json.items():\n",
    "    new_value_list = np.zeros(len(truth_keys))\n",
    "    counter = 1\n",
    "    for val in value:\n",
    "        for i in range(len(truth_keys)):\n",
    "            if val == truth_keys[i]:\n",
    "                counter += 1\n",
    "                new_value_list[i] = 1/math.log(counter, 2)\n",
    "    hybrid_results_all[key] = new_value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_ndcg = {}\n",
    "hybrid_ap = {}\n",
    "hybrid_f1 = {}\n",
    "for (true_key, true_value), (es_key, es_value) in zip(truth_dict_all.items(), hybrid_results_all.items()):\n",
    "    hybrid_ndcg[true_key] = ndcg_score([true_value], [es_value])\n",
    "    hybrid_ap[true_key] = average_precision_score(true_value, es_value, pos_label=0)\n",
    "for (true_key, true_value), (es_key, es_value) in zip(truth_dict_all.items(), binary_hybrid_results_all.items()):\n",
    "    hybrid_f1[true_key] = f1_score(true_value, es_value, zero_division=0, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_eval = pd.DataFrame(data=[hybrid_ndcg, hybrid_ap, hybrid_f1]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_eval = hybrid_eval.rename({0:\"NDCG\", 1:\"AP\", 2:\"F1\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hybrid_mean_scores = hybrid_eval.mean()\n",
    "Hybrid_mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "sns.kdeplot(hybrid_eval.NDCG, alpha=.1, shade=True, label='NDCG')\n",
    "sns.kdeplot(hybrid_eval.AP, alpha=.1, shade=True,label='AP')\n",
    "sns.kdeplot(hybrid_eval.F1,  alpha=.1, shade=True,label='F1')\n",
    "plt.legend()\n",
    "plt.title('Ranking Metric Performance, Hybrid Index', fontsize=20)\n",
    "plt.xlabel('Score Distribution', fontsize=16)\n",
    "plt.ylabel('Score Density', fontsize=16)\n",
    "plt.xlim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which comments were scored poorly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorf1 = hybrid_eval.query(\"F1 < 0.5\").F1\n",
    "poorf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorndcg = hybrid_eval.query(\"NDCG < 0.3 & NDCG > 0\").NDCG\n",
    "poorndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorf1_comments = {key:comment for key, comment in comments2018.items() if key in poorf1}\n",
    "{key:len(comment) for key, comment in poorf1_comments.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorf1_comments_truth = {key:matches for key, matches in truth_dict.items() if key in poorf1}\n",
    "poorf1_comments_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorndcg_comments = {key:comment for key, comment in comments2018.items() if key in poorndcg}\n",
    "{key:len(comment) for key, comment in poorndcg_comments.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poorndcg_comments_truth = {key:matches for key, matches in truth_dict.items() if key in poorndcg}\n",
    "poorndcg_comments_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cummulative_gain(truth, pred):\n",
    "    counter = 0\n",
    "    for i in truth:\n",
    "        if i in pred:\n",
    "            counter +=1\n",
    "    return counter\n",
    "def Discounted_Cummulative_gain(truth, pred):\n",
    "    DCG = 0\n",
    "    for i,j in enumerate(pred):\n",
    "        if j in truth:\n",
    "            DCG += (1/(math.log(i+2,2)))\n",
    "    return DCG\n",
    "def Ideal_discounted_cummulative_gain(truth, pred):\n",
    "    counter = 0\n",
    "    IDCG = 0\n",
    "    for i in truth:\n",
    "        if i in pred:\n",
    "            counter +=1\n",
    "    for i in range(counter):\n",
    "        IDCG += (1/(math.log(i+2,2)))\n",
    "    return IDCG\n",
    "def nDiscounted_Cummulative_gain(truth, pred):\n",
    "    x = Ideal_discounted_cummulative_gain(truth, pred)\n",
    "    y = Discounted_Cummulative_gain(truth, pred)\n",
    "    return y/(x+0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(truth, pred):\n",
    "    runn = 0\n",
    "    cum_gain = 0\n",
    "    for i, j in enumerate(truth):\n",
    "        if j in pred:\n",
    "            cum_gain +=1\n",
    "            runn = runn + cum_gain/(i+1)\n",
    "    average_pred = runn / (cum_gain + 0.0001)\n",
    "    return average_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_1_score(truth, pred):\n",
    "    AP = average_precision(truth, pred)\n",
    "    F_1 = AP/(AP + 1)\n",
    "    return 2*F_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headers Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = {}\n",
    "DCG = {}\n",
    "iDCG = {}\n",
    "nDCG = {}\n",
    "AP = {}\n",
    "F_1 = {}\n",
    "MAP = 0\n",
    "count = 0\n",
    "for (i,(k,j)) in zip(truth_dict.values(),header_results_json.items()):\n",
    "    CG[k] = Cummulative_gain(i,j)\n",
    "    DCG[k] = Discounted_Cummulative_gain(i,j)\n",
    "    iDCG[k] = Ideal_discounted_cummulative_gain(i,j)\n",
    "    nDCG[k] = nDiscounted_Cummulative_gain(i,j)\n",
    "    AP[k] = average_precision(i,j)\n",
    "    F_1[k] = F_1_score(i,j)\n",
    "    count +=1\n",
    "    MAP +=AP[k]\n",
    "Model_eval = pd.DataFrame(data=[CG, DCG, iDCG, nDCG, AP, F_1])\n",
    "MAP/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_eval = Model_eval.transpose().rename({0:'CG',1:'DCG',2:'iDCG',3:'nDCG',4:'AP',5:'F1'}, axis=1)\n",
    "Model_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_scores = Model_eval.mean()\n",
    "Mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "\n",
    "sns.kdeplot(Model_eval.nDCG, alpha=.1, shade=True, label='nDCG')\n",
    "sns.kdeplot(Model_eval.AP, alpha=.1, shade=True,label='AP')\n",
    "sns.kdeplot(Model_eval.F1,  alpha=.1, shade=True,label='F1')\n",
    "plt.legend()\n",
    "plt.title('Ranking Metric Performance, Headers Index', fontsize=20)\n",
    "plt.xlabel('Score Distribution', fontsize=16)\n",
    "plt.ylabel('Score Density', fontsize=16)\n",
    "plt.xlim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = {}\n",
    "DCG = {}\n",
    "iDCG = {}\n",
    "nDCG = {}\n",
    "AP = {}\n",
    "F_1 = {}\n",
    "MAP = 0\n",
    "count = 0\n",
    "for (i,(k,j)) in zip(truth_dict.values(),hybrid_results_json.items()):\n",
    "    CG[k] = Cummulative_gain(i,j)\n",
    "    DCG[k] = Discounted_Cummulative_gain(i,j)\n",
    "    iDCG[k] = Ideal_discounted_cummulative_gain(i,j)\n",
    "    nDCG[k] = nDiscounted_Cummulative_gain(i,j)\n",
    "    AP[k] = average_precision(i,j)\n",
    "    F_1[k] = F_1_score(i,j)\n",
    "    count += 1\n",
    "    MAP += AP[k]\n",
    "Model_eval2 = pd.DataFrame(data=[CG, DCG, iDCG, nDCG, AP, F_1])\n",
    "MAP/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model_eval2 = Model_eval2.transpose().rename({0:'CG',1:'DCG',2:'iDCG',3:'nDCG',4:'AP',5:'F1'}, axis=1)\n",
    "Model_eval2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean_scores2 = Model_eval2.mean()\n",
    "Mean_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = pd.DataFrame(data=[Mean_scores, Mean_scores2])\n",
    "mean_df=mean_df.rename({0:'headers',1:'hybrid'},axis=0)\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14,10))\n",
    "\n",
    "sns.kdeplot(Model_eval2.nDCG, alpha=.1, shade=True, label='nDCG')\n",
    "sns.kdeplot(Model_eval2.AP, alpha=.1, shade=True, label='AP')\n",
    "sns.kdeplot(Model_eval2.F1,  alpha=.1, shade=True, label='F1')\n",
    "plt.legend()\n",
    "plt.title('Ranking Metric Performance, Hybrid Index', fontsize=20)\n",
    "plt.xlabel('Score Distribution', fontsize=16)\n",
    "plt.ylabel('Score Density', fontsize=16)\n",
    "plt.xlim(0,1);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
