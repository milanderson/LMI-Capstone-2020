{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from sklearn.metrics import f1_score as f1, confusion_matrix as confusion, plot_roc_curve as roc\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Comments and True Classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unique_comments2018.json\") as f:\n",
    "    texts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {key:value.replace(\"\\r\", \" \").replace(\"\\n\", \" \").replace(\"\\s\", \" \") for key, value in texts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in texts.items():\n",
    "    texts[key] = ''.join(c for c in value if c in string.printable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_url = \"https://mikeanders.org/data/CMS/CMS-2018-0101-0001/CMS-1701-P%20Comment%20MetaData.csv\"\n",
    "data = pd.read_csv(metadata_url, usecols=range(0,36))[:468] #ignore last few columns and blank rows at end of csv \n",
    "data = data.rename(columns=lambda x: x.strip()) #strip whitespace from columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data10 = data.fillna(0) #fill NaN with 0\n",
    "section_cols = data10.columns[3:] \n",
    "data10[section_cols] = data10[section_cols].replace([\"Y\"], 1) #replace Y with 1 in approriate columns\n",
    "data11 = data10.copy()\n",
    "section_cols1  = data11.columns[3:] \n",
    "data11[section_cols1] = np.where((data11[section_cols1]  != 1),0,data11[section_cols1] )\n",
    "\n",
    "# Combining columns for index matching: (A6b, A6b.1, = A6b),  (C3b, C3b.1'= C3b) ('A7', 'A7.1', 'A7.2', = A7b, a7c),  (F = F2, F3)\n",
    "data11['A6b'] = (data11['A6b'] + data11['A6b.1'])\n",
    "data11['A6b'] = data11['A6b'].replace(2,1)\n",
    "data11['C3b'] = (data11['C3b'] + data11['C3b.1'])\n",
    "data11['C3b'] = data11['C3b'].replace(2,1)\n",
    "data11['A7'] = (data11['A7'] + data11['A7.1'] + data11['A7.2'])\n",
    "data11['A7'] = data11['A7'].replace(2,1)\n",
    "data11['A7'] = data11['A7'].replace(3,1)\n",
    "data11 = data11.drop(['A6b.1', 'C3b.1', 'A7.1', 'A7.2'], axis = 1)\n",
    "\n",
    "data11.Name = [name.split('DRAFT-')[1].split('-')[0] for name in data11.Name]\n",
    "data11 = data11.rename(columns=lambda x: x.lower())\n",
    "section_cols1 = data11.columns[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data11 = data11.loc[data11['name'].isin(texts.keys())]\n",
    "data11[\"comment\"] = texts.values() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data11.sample(frac=.75, random_state=44)\n",
    "test = data11.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = list(train.comment)\n",
    "test_texts = list(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>organization name / submitter name</th>\n",
       "      <th>submitter state</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>a4b</th>\n",
       "      <th>a4c</th>\n",
       "      <th>a5b</th>\n",
       "      <th>a5c</th>\n",
       "      <th>a5d</th>\n",
       "      <th>...</th>\n",
       "      <th>d3d</th>\n",
       "      <th>d4</th>\n",
       "      <th>e2</th>\n",
       "      <th>e3</th>\n",
       "      <th>e4</th>\n",
       "      <th>e5</th>\n",
       "      <th>e6</th>\n",
       "      <th>e7</th>\n",
       "      <th>f</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0467</td>\n",
       "      <td>Washington State Hospital Association</td>\n",
       "      <td>WA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>see attached file(s)october 15, 2018 ms. seema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0408</td>\n",
       "      <td>Dana McCalley</td>\n",
       "      <td>FL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>diabetic eye exam measure should be retired. t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0207</td>\n",
       "      <td>Mayo Clinic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>see attached file(s) mayo clinic 200 first str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0267</td>\n",
       "      <td>OneHealth Nebraska ACO, LLC</td>\n",
       "      <td>NE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>see attached file(s) cms should modify the med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0009</td>\n",
       "      <td>Sherman Jew</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>making and enforcing more complex and expensiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0374</td>\n",
       "      <td>The Queen's Health System</td>\n",
       "      <td>HI</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>please see attached for comments. ms. seema ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0195</td>\n",
       "      <td>Michael Saito</td>\n",
       "      <td>WI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>please see the attached document with epic's c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0347</td>\n",
       "      <td>American Association of Nurse Practitioners</td>\n",
       "      <td>VA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>please find the attached comments of the ameri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0249</td>\n",
       "      <td>High Value Healcare Collaborative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>see attached file(s) high value healthcare col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0253</td>\n",
       "      <td>Innova Health System</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>see attached file(s)   signature  october 15, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     name           organization name / submitter name submitter state  a2  \\\n",
       "465  0467        Washington State Hospital Association              WA   0   \n",
       "406  0408                                Dana McCalley              FL   0   \n",
       "205  0207                                  Mayo Clinic               0   0   \n",
       "265  0267                  OneHealth Nebraska ACO, LLC              NE   1   \n",
       "7    0009                                  Sherman Jew              WI   0   \n",
       "..    ...                                          ...             ...  ..   \n",
       "372  0374                    The Queen's Health System              HI   0   \n",
       "193  0195                                Michael Saito              WI   0   \n",
       "345  0347  American Association of Nurse Practitioners              VA   1   \n",
       "247  0249            High Value Healcare Collaborative               0   0   \n",
       "251  0253                         Innova Health System               0   0   \n",
       "\n",
       "     a3  a4b  a4c  a5b  a5c  a5d  ...  d3d  d4  e2  e3  e4  e5  e6  e7  f  \\\n",
       "465   0    0    0    0    0    0  ...    0   0   0   0   0   0   0   0  0   \n",
       "406   0    0    0    0    0    0  ...    0   0   0   0   0   0   0   0  0   \n",
       "205   1    0    1    0    0    0  ...    0   0   1   1   0   0   0   0  0   \n",
       "265   1    0    1    1    0    0  ...    0   0   0   0   0   0   0   0  0   \n",
       "7     0    0    0    1    0    0  ...    0   0   0   0   0   0   0   0  0   \n",
       "..   ..  ...  ...  ...  ...  ...  ...  ...  ..  ..  ..  ..  ..  ..  .. ..   \n",
       "372   1    0    0    1    0    0  ...    0   0   0   0   0   0   0   0  0   \n",
       "193   0    0    0    0    0    0  ...    0   0   0   0   0   1   0   0  0   \n",
       "345   1    0    0    0    0    0  ...    0   0   1   0   0   0   0   0  0   \n",
       "247   1    0    1    0    0    0  ...    0   0   0   0   0   0   0   0  0   \n",
       "251   1    0    0    1    0    0  ...    0   0   0   0   0   0   1   0  0   \n",
       "\n",
       "                                               comment  \n",
       "465  see attached file(s)october 15, 2018 ms. seema...  \n",
       "406  diabetic eye exam measure should be retired. t...  \n",
       "205  see attached file(s) mayo clinic 200 first str...  \n",
       "265  see attached file(s) cms should modify the med...  \n",
       "7    making and enforcing more complex and expensiv...  \n",
       "..                                                 ...  \n",
       "372  please see attached for comments. ms. seema ve...  \n",
       "193  please see the attached document with epic's c...  \n",
       "345  please find the attached comments of the ameri...  \n",
       "247  see attached file(s) high value healthcare col...  \n",
       "251  see attached file(s)   signature  october 15, ...  \n",
       "\n",
       "[70 rows x 33 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a2      32\n",
       "a3      46\n",
       "a4b      4\n",
       "a4c     29\n",
       "a5b     32\n",
       "a5c     17\n",
       "a5d     16\n",
       "a6b     12\n",
       "a6c     10\n",
       "a6d2     2\n",
       "a6d3     7\n",
       "a7      24\n",
       "b2a     27\n",
       "b2b     24\n",
       "c2      27\n",
       "c3a     20\n",
       "c3b     17\n",
       "d2      39\n",
       "d3b     26\n",
       "d3c     16\n",
       "d3d      3\n",
       "d4       1\n",
       "e2      16\n",
       "e3      10\n",
       "e4       5\n",
       "e5      25\n",
       "e6      20\n",
       "e7       9\n",
       "f        2\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data11.sum(axis=0)[section_cols1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify One Rule Section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords = ['!', '\"', \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"*\", \"+\", \",\", \"-\", \".\", \"/\", \":\", \";\", \"<\", \"=\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"`\", \"{\", \"|\", \"}\", \"~\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vector = CountVectorizer(tokenizer=nltk.RegexpTokenizer(r\"\\w+\").tokenize, ngram_range=(1,1), stop_words='english')\n",
    "\n",
    "x_train = bow_vector.fit_transform(train_texts)\n",
    "y_train = np.array(train.a2)\n",
    "\n",
    "x_test = bow_vector.transform(test_texts)\n",
    "y_test = np.array(test.a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 1], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SGDClassifier(random_state=44)\n",
    "svm.fit(X=x_train, y=y_train)\n",
    "svm_preds = svm.predict(x_test)\n",
    "svm_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_f1 = f1(y_test, svm_preds)\n",
    "svm_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  2],\n",
       "       [ 6,  6]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_confusion = confusion(y_test, svm_preds)\n",
    "svm_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Most Significant Words for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mil',\n",
       " 'county',\n",
       " 'telehealth',\n",
       " 'health',\n",
       " 'mssp',\n",
       " 'advocate',\n",
       " 'shared',\n",
       " 'acos',\n",
       " 'e',\n",
       " 'participants',\n",
       " 'ama',\n",
       " 'aurora',\n",
       " 'spending',\n",
       " 'texas',\n",
       " 'savings']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = svm.coef_[0]\n",
    "top_fifteen = np.argpartition(coefs, -15)[-15:]\n",
    "[(bow_vector.get_feature_names()[feature]) for feature in top_fifteen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "boost.fit(x_train, y_train)\n",
    "boost_preds = boost.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_f1 = f1(y_test, svm_preds)\n",
    "boost_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 3],\n",
       "       [8, 4]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_confusion = confusion(y_test, boost_preds)\n",
    "boost_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Most Significant Words for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['waivers',\n",
       " 'successful',\n",
       " 'savings',\n",
       " 'cause',\n",
       " 'capital',\n",
       " 'assignment',\n",
       " 'behalf',\n",
       " 'chief',\n",
       " 'choose',\n",
       " 'attributed',\n",
       " 'verma',\n",
       " 'e',\n",
       " 'medicare',\n",
       " 'p',\n",
       " '1']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_top15 = np.argsort(-boost.feature_importances_)[0:15]\n",
    "[(bow_vector.get_feature_names()[feature]) for feature in boost_top15] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify All Rule Sections - TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer=nltk.RegexpTokenizer(r\"\\w+\").tokenize, ngram_range=(1,1), stop_words=\"english\")\n",
    "\n",
    "x_train = tfidf_vector.fit_transform(train_texts)\n",
    "y_train = np.array(train[section_cols1])\n",
    "\n",
    "x_test = tfidf_vector.transform(test_texts)\n",
    "y_test = np.array(test[section_cols1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "multi_boost = MultiOutputClassifier(boost)\n",
    "\n",
    "multi_boost.fit(x_train, y_train)\n",
    "\n",
    "multi_boost_preds = multi_boost.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_boost_f1 = f1(y_test, multi_boost_preds, zero_division=0, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a2': 0.6666666666666666,\n",
       " 'a3': 0.6666666666666666,\n",
       " 'a4b': 0.0,\n",
       " 'a4c': 0.75,\n",
       " 'a5b': 0.6666666666666665,\n",
       " 'a5c': 0.25,\n",
       " 'a5d': 0.4444444444444445,\n",
       " 'a6b': 0.6666666666666666,\n",
       " 'a6c': 0.0,\n",
       " 'a6d2': 0.0,\n",
       " 'a6d3': 0.0,\n",
       " 'a7': 0.6153846153846154,\n",
       " 'b2a': 0.6666666666666666,\n",
       " 'b2b': 0.7692307692307692,\n",
       " 'c2': 0.5714285714285715,\n",
       " 'c3a': 0.2,\n",
       " 'c3b': 0.6666666666666665,\n",
       " 'd2': 0.6923076923076923,\n",
       " 'd3b': 0.6666666666666666,\n",
       " 'd3c': 0.0,\n",
       " 'd3d': 0.0,\n",
       " 'd4': 0.0,\n",
       " 'e2': 0.4444444444444444,\n",
       " 'e3': 1.0,\n",
       " 'e4': 0.0,\n",
       " 'e5': 0.6666666666666666,\n",
       " 'e6': 0.7692307692307693,\n",
       " 'e7': 0.0,\n",
       " 'f': 0.0}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = {sec:score for (sec, score) in zip(section_cols1, list(multi_boost_f1))}\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4082691255105048"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(multi_boost_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identifying Most Significant Words for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:749: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return all_features / all_features.sum()\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "for boost in multi_boost.estimators_:\n",
    "    boost_top10 = np.argsort(-boost.feature_importances_)[0:10]\n",
    "    features.append([(bow_vector.get_feature_names()[feature]) for feature in boost_top10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'boost_features' (dict)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a2': (0.6666666666666666,\n",
       "  ['waivers',\n",
       "   'participants',\n",
       "   'choose',\n",
       "   'cause',\n",
       "   'mechanism',\n",
       "   'participating',\n",
       "   'file',\n",
       "   'success',\n",
       "   'telehealth',\n",
       "   'accountable']),\n",
       " 'a3': (0.6666666666666666,\n",
       "  ['receive',\n",
       "   'hospitals',\n",
       "   'levels',\n",
       "   'revenue',\n",
       "   'agreement',\n",
       "   '1701',\n",
       "   'shared',\n",
       "   'recommend',\n",
       "   'low',\n",
       "   'seema']),\n",
       " 'a4b': (0.0,\n",
       "  ['beneficiary',\n",
       "   'avoid',\n",
       "   'cms1701p',\n",
       "   'election',\n",
       "   'patient',\n",
       "   '26',\n",
       "   'focused',\n",
       "   'build',\n",
       "   'date',\n",
       "   'policy']),\n",
       " 'a4c': (0.75,\n",
       "  ['retrospective',\n",
       "   'prospective',\n",
       "   'choose',\n",
       "   'waivers',\n",
       "   'annually',\n",
       "   '2',\n",
       "   'aco',\n",
       "   'choice',\n",
       "   'benchmark',\n",
       "   '1701']),\n",
       " 'a5b': (0.6666666666666665,\n",
       "  ['revenue',\n",
       "   'day',\n",
       "   'large',\n",
       "   '21244',\n",
       "   'low',\n",
       "   'real',\n",
       "   'behalf',\n",
       "   'result',\n",
       "   'file',\n",
       "   'attached']),\n",
       " 'a5c': (0.25,\n",
       "  ['complex',\n",
       "   'oppose',\n",
       "   'percent',\n",
       "   'dear',\n",
       "   'determining',\n",
       "   'entity',\n",
       "   'regardless',\n",
       "   'reduction',\n",
       "   'participation',\n",
       "   'rule']),\n",
       " 'a5d': (0.4444444444444445,\n",
       "  ['telehealth',\n",
       "   'infrastructure',\n",
       "   'losses',\n",
       "   'community',\n",
       "   'agree',\n",
       "   'recommend',\n",
       "   'greater',\n",
       "   'participating',\n",
       "   'expenditures',\n",
       "   'based']),\n",
       " 'a6b': (0.6666666666666666,\n",
       "  ['mlr',\n",
       "   'ensure',\n",
       "   'assigned',\n",
       "   'date',\n",
       "   'beneficiary',\n",
       "   'participations',\n",
       "   'participation',\n",
       "   'participating',\n",
       "   'participates',\n",
       "   'participated']),\n",
       " 'a6c': (0.0,\n",
       "  ['funds',\n",
       "   'mechanism',\n",
       "   'attractive',\n",
       "   '1701',\n",
       "   'administrator',\n",
       "   'mssp',\n",
       "   'healthcare',\n",
       "   'sided',\n",
       "   'o',\n",
       "   'rule']),\n",
       " 'a6d2': (0.0,\n",
       "  ['0',\n",
       "   'participating',\n",
       "   'participates',\n",
       "   'participated',\n",
       "   'participate',\n",
       "   'participants',\n",
       "   'participant',\n",
       "   'partially',\n",
       "   'partial',\n",
       "   'parsed']),\n",
       " 'a6d3': (0.0,\n",
       "  ['useful',\n",
       "   'enhancements',\n",
       "   'insufficient',\n",
       "   'patient',\n",
       "   'possible',\n",
       "   '4',\n",
       "   'fee',\n",
       "   'address',\n",
       "   'methodology',\n",
       "   '3']),\n",
       " 'a7': (0.6153846153846154,\n",
       "  ['july',\n",
       "   '30',\n",
       "   'vs',\n",
       "   '2019',\n",
       "   'date',\n",
       "   '10',\n",
       "   'enhanced',\n",
       "   'level',\n",
       "   'performance',\n",
       "   '2020']),\n",
       " 'b2a': (0.6666666666666666,\n",
       "  ['snf',\n",
       "   'methodology',\n",
       "   'adjustment',\n",
       "   'changes',\n",
       "   'forward',\n",
       "   'submit',\n",
       "   '3',\n",
       "   'receive',\n",
       "   'pleased',\n",
       "   'assignment']),\n",
       " 'b2b': (0.7692307692307692,\n",
       "  ['telehealth',\n",
       "   'association',\n",
       "   '16',\n",
       "   'proposal',\n",
       "   'voluntarily',\n",
       "   'health',\n",
       "   '1701',\n",
       "   'support',\n",
       "   'risk',\n",
       "   'option']),\n",
       " 'c2': (0.5714285714285715,\n",
       "  ['patient',\n",
       "   'variable',\n",
       "   'ensure',\n",
       "   'unnecessary',\n",
       "   'operations',\n",
       "   'beneficiary',\n",
       "   'community',\n",
       "   'medicare',\n",
       "   '16',\n",
       "   'health']),\n",
       " 'c3a': (0.2,\n",
       "  ['stability',\n",
       "   'urges',\n",
       "   'addition',\n",
       "   'investments',\n",
       "   'number',\n",
       "   'provides',\n",
       "   'act',\n",
       "   'feedback',\n",
       "   'language',\n",
       "   'sincerely']),\n",
       " 'c3b': (0.6666666666666665,\n",
       "  ['opt',\n",
       "   'voluntarily',\n",
       "   'primary',\n",
       "   'adjustment',\n",
       "   'attestation',\n",
       "   'aco',\n",
       "   'services',\n",
       "   '5',\n",
       "   'provider',\n",
       "   'participate']),\n",
       " 'd2': (0.6923076923076923,\n",
       "  ['benchmark',\n",
       "   'periods',\n",
       "   'additional',\n",
       "   'benchmarking',\n",
       "   'vs',\n",
       "   'processes',\n",
       "   '1701',\n",
       "   'analysis',\n",
       "   'addition',\n",
       "   'department']),\n",
       " 'd3b': (0.6666666666666666,\n",
       "  ['earlier',\n",
       "   'benchmarking',\n",
       "   'regardless',\n",
       "   'organization',\n",
       "   '16',\n",
       "   'behalf',\n",
       "   'accurately',\n",
       "   'ms',\n",
       "   '000',\n",
       "   'medicaid']),\n",
       " 'd3c': (0.0,\n",
       "  ['historical',\n",
       "   'incentives',\n",
       "   'defining',\n",
       "   'center',\n",
       "   'approximately',\n",
       "   'accurate',\n",
       "   'www',\n",
       "   'conditions',\n",
       "   'better',\n",
       "   '16']),\n",
       " 'd3d': (0.0,\n",
       "  ['achieved',\n",
       "   '18',\n",
       "   '8',\n",
       "   'importance',\n",
       "   'possible',\n",
       "   'physician',\n",
       "   'hospitals',\n",
       "   '3',\n",
       "   '0',\n",
       "   'better']),\n",
       " 'd4': (0.0,\n",
       "  ['0',\n",
       "   'participating',\n",
       "   'participates',\n",
       "   'participated',\n",
       "   'participate',\n",
       "   'participants',\n",
       "   'participant',\n",
       "   'partially',\n",
       "   'partial',\n",
       "   'parsed']),\n",
       " 'e2': (0.4444444444444444,\n",
       "  ['voluntary',\n",
       "   'opt',\n",
       "   '100',\n",
       "   'retrospective',\n",
       "   'beneficiary',\n",
       "   'following',\n",
       "   'responsible',\n",
       "   'primary',\n",
       "   'increased',\n",
       "   'choice']),\n",
       " 'e3': (1.0,\n",
       "  ['beginning',\n",
       "   'codes',\n",
       "   'added',\n",
       "   'alliance',\n",
       "   'percent',\n",
       "   'high',\n",
       "   'path',\n",
       "   'experience',\n",
       "   'policy',\n",
       "   'unnecessary']),\n",
       " 'e4': (0.0,\n",
       "  ['0',\n",
       "   '000',\n",
       "   '2012',\n",
       "   '2014',\n",
       "   '2019',\n",
       "   'baseline',\n",
       "   'category',\n",
       "   'december',\n",
       "   'changes',\n",
       "   'independent']),\n",
       " 'e5': (0.6666666666666666,\n",
       "  ['medication',\n",
       "   'measures',\n",
       "   'loss',\n",
       "   'comprehensive',\n",
       "   'success',\n",
       "   'disease',\n",
       "   'access',\n",
       "   'attached',\n",
       "   'program',\n",
       "   'rates']),\n",
       " 'e6': (0.7692307692307693,\n",
       "  ['cehrt',\n",
       "   'clarify',\n",
       "   'promoting',\n",
       "   '2',\n",
       "   'adjustment',\n",
       "   'behalf',\n",
       "   'record',\n",
       "   '50',\n",
       "   'proposal',\n",
       "   'cms']),\n",
       " 'e7': (0.0,\n",
       "  ['pharmacy',\n",
       "   'mips',\n",
       "   'aligned',\n",
       "   'include',\n",
       "   'sets',\n",
       "   'comprehensive',\n",
       "   'development',\n",
       "   'encourage',\n",
       "   'use',\n",
       "   'attention']),\n",
       " 'f': (0.0,\n",
       "  ['clarification',\n",
       "   'understanding',\n",
       "   'currently',\n",
       "   'current',\n",
       "   'based',\n",
       "   'risk',\n",
       "   'participation',\n",
       "   'participating',\n",
       "   'participates',\n",
       "   'participated'])}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = {sec:feature_list for (sec, feature_list) in zip(section_cols1, features)}\n",
    "boost_features = {key:(value,features) for (key, value), (key1, features) in zip(scores.items(), important_features.items())}\n",
    "\n",
    "%store boost_features\n",
    "boost_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
